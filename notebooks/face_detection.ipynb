{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb63943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from save_file import save_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a177439",
   "metadata": {},
   "source": [
    "# Process the face detection on a video\n",
    "1. Load the numpy array generated from a video\n",
    "1. Process the face detection\n",
    "1. Visual check of the performances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7036c2",
   "metadata": {},
   "source": [
    "## Load the numpy array : 3D + 3D numpy with colors or 3D if gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f6410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLOR = True \n",
    "SHOW_DET_FACES = True\n",
    "fps_np = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e0a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLOR = True \n",
    "SHOW_DET_FACES = True\n",
    "fps_np = 1.\n",
    "\n",
    "# Load the numpy array \n",
    "path_arrays = \"../data/arrays/\"\n",
    "array_name = 'TH_GNS_' + str(int(fps_np)) + 'fps'\n",
    "#array_name = 'EJ_GNS_' + str(int(fps_np)) + 'fps'\n",
    "\n",
    "if USE_COLOR:\n",
    "    color = '_RGB'\n",
    "else:\n",
    "    color = '_Gray'\n",
    "    \n",
    "# Load the numpy video \n",
    "file_in_np = path_arrays + array_name + color + '.npy'\n",
    "video_np =np.load(file = file_in_np)\n",
    "video_np = video_np.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files : crop faces and metadata\n",
    "file_out_np = path_arrays + array_name + '.npy'\n",
    "file_out_json = path_arrays + array_name + '.json'\n",
    "\n",
    "# Hyperparamters for cropping\n",
    "\n",
    "# Contour margin for the face cropping\n",
    "margin = 0\n",
    "# mininum size of the face to be\n",
    "min_face_size = 20\n",
    "\n",
    "metadata_video = {'video_uuid':  uuid.uuid4(),\n",
    "                  'video_uri': None,\n",
    "                  'filename_metadata': file_out_json,\n",
    "                  'filename_crop_faces': file_out_np,\n",
    "                  'use_color': USE_COLOR,\n",
    "                  'crop_margin': margin,\n",
    "                  'min_face_size': min_face_size,\n",
    "                  'fps': fps_np}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587c5c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frame : 153\n",
      "Frame size WxH : 320x180\n",
      "Colors : 3\n"
     ]
    }
   ],
   "source": [
    "# check the size of the video \n",
    "if USE_COLOR:\n",
    "    nb_frame, height, width, color = video_np.shape\n",
    "else:\n",
    "    nb_frame, height, width = video_np.shape\n",
    "    color = 1\n",
    "\n",
    "print('Number of frame : ' + str(nb_frame))\n",
    "print('Frame size WxH : ' + str(width) + 'x' + str(height))\n",
    "print('Colors : ' + str(color))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0cd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_screen():\n",
    "    # close the window\n",
    "    cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb35903",
   "metadata": {},
   "source": [
    "## Process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8daa5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters \n",
    "\n",
    "# contour margin for the face cropping\n",
    "margin = 0\n",
    "\n",
    "# mininum size of the face to be \n",
    "min_face_size = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6887b6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 550 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a8ddba4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "detector = MTCNN(min_face_size=min_face_size)\n",
    "\n",
    "# outputs\n",
    "crop_faces = []\n",
    "no_face = []\n",
    "video_fd = np.copy(video_np)\n",
    "\n",
    "for idx, frame in enumerate(video_np):\n",
    "\n",
    "    detection_face = detector.detect_faces(frame)\n",
    "\n",
    "    if len(detection_face) == 0:\n",
    "\n",
    "        no_face.append(frame)\n",
    "\n",
    "        video_fd[idx, :] = frame\n",
    "\n",
    "    else:\n",
    "\n",
    "        for face in detection_face:\n",
    "\n",
    "            face_idx = face['box']\n",
    "            y = int(max(face_idx[0] - margin/2, 0))\n",
    "            x = int(max(face_idx[1] - margin/2, 0))\n",
    "            h = face_idx[2] + margin\n",
    "            w = face_idx[3] + margin\n",
    "\n",
    "            # save the crop images\n",
    "            crop_face = frame[x:x+w, y:y+h, :]\n",
    "            crop_faces.append(crop_face)\n",
    "\n",
    "            # put a block box on the faces to make the detection more visible\n",
    "            # img_show[x:x+w, y:y+h, :] = 0\n",
    "\n",
    "            video_fd[idx, x:x+w, y, :] = 255\n",
    "            video_fd[idx, x:x+w, y+h, :] = 255\n",
    "            video_fd[idx, x, y:y+h, :] = 255\n",
    "            video_fd[idx, x+w, y:y+h, :] = 255\n",
    "\n",
    "            video_fd[(idx,) + face['keypoints']['right_eye'][::-1]] = 255\n",
    "            video_fd[(idx,) + face['keypoints']['left_eye'][::-1]] = 255\n",
    "            video_fd[(idx,) + face['keypoints']['nose'][::-1]] = 255\n",
    "            video_fd[(idx,) + face['keypoints']['mouth_left'][::-1]] = 255\n",
    "            video_fd[(idx,) + face['keypoints']['mouth_right'][::-1]] = 255\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "739cee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate a .gif\n",
    "gif = False\n",
    "if gif:\n",
    "    path_arrays = \"../data/arrays/\"\n",
    "    gif_out = path_arrays + 'TH_GNS.gif'\n",
    "\n",
    "    imgs = [Image.fromarray(img) for img in video_fd.astype(np.uint8)]\n",
    "    # duration is the number of milliseconds between frames; this is 40 frames per second\n",
    "    imgs[0].save(gif_out, save_all=True, append_images=imgs[1:], duration=5, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44bae9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "press a key to start\n"
     ]
    }
   ],
   "source": [
    "# Show the video with detected faces\n",
    "idx = 0 \n",
    "for frame in video_fd:\n",
    "   \n",
    "    cv2.imshow('face detection test', frame)\n",
    "    aa = cv2.waitKey(300)\n",
    "    \n",
    "    if idx == 0:\n",
    "        a =input('press a key to start')\n",
    "    idx +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "463e4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d921ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames with no face dectected : 29\n"
     ]
    }
   ],
   "source": [
    "# show the frame with no face detected\n",
    "print(\"Number of frames with no face dectected : \" + str(len(no_face)) )\n",
    "for face in no_face:\n",
    "    cv2.namedWindow('image',cv2.WINDOW_NORMAL) \n",
    "    cv2.resizeWindow('image',width,height)\n",
    "    cv2.imshow('image', face)\n",
    "    aa = cv2.waitKey(100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f2c9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "962a6ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces dectected : 201\n"
     ]
    }
   ],
   "source": [
    "# show the detected faces\n",
    "print(\"Number of faces dectected : \" + str(len(crop_faces)) )\n",
    "for face in crop_faces:\n",
    "    cv2.namedWindow('image',cv2.WINDOW_NORMAL) \n",
    "    cv2.resizeWindow('image',600,600)\n",
    "    cv2.imshow('image', face)\n",
    "    aa = cv2.waitKey(100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b1c95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e734d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(file_out_np, data_np, file_out_json, metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_reco",
   "language": "python",
   "name": "face_reco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
